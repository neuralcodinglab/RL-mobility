{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "import os, sys\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from IPython.display import Audio\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchsummary import summary\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# local files\n",
    "sys.path.insert(0, '../')\n",
    "import pyClient\n",
    "import utils\n",
    "import model\n",
    "from model import Transition\n",
    "import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameters\n",
    "BATCH_SIZE = 128 #original 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.95\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY_steps = 4000 \n",
    "EPS_DECAY = (EPS_START - EPS_END)/EPS_DECAY_steps\n",
    "REPLAY_START_SIZE =  1500\n",
    "TARGET_UPDATE = 10 #episodes\n",
    "DEVICE = 'cuda:0'\n",
    "MEMORY_CAPACITY = 12000\n",
    "\n",
    "# agent = model.DoubleDQNAgent(imsize=IMSIZE,\n",
    "#                  in_channels=STACK_SIZE,\n",
    "#                  n_actions=N_ACTIONS,\n",
    "#                  memory_capacity=MEMORY_CAPACITY,\n",
    "#                  eps_start=EPS_START,\n",
    "#                  eps_end=EPS_END,\n",
    "#                  eps_delta=EPS_DECAY,\n",
    "#                  gamma_discount = GAMMA,\n",
    "#                  batch_size = BATCH_SIZE,\n",
    "#                  device=DEVICE)\n",
    "\n",
    "\n",
    "# Environment parameters\n",
    "IMSIZE = 128\n",
    "STACK_SIZE = 4\n",
    "N_ACTIONS = 3\n",
    "IP  = \"127.0.0.1\" # Ip address that the TCP/IP interface listens to\n",
    "PORT = 13000       # Port number that the TCP/IP interface listens to\n",
    "\n",
    "environment = pyClient.Environment(ip = IP, port = PORT, size = IMSIZE) \n",
    "\n",
    "\n",
    "# Optimizer Parameters\n",
    "LR_DQN = 0.01\n",
    "\n",
    "# optimizer = optim.Adam(agent.policy_net.parameters(), lr = LR_DQN)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing\n",
    "class ImageProcessor(object):\n",
    "    def __init__(self, phosphene_resolution=None, imsize=128):\n",
    "        \"\"\" @TODO \n",
    "        - Extended image processing\n",
    "        \"\"\"\n",
    "        self.imsize = imsize\n",
    "        if phosphene_resolution is not None:\n",
    "            self.simulator = utils.PhospheneSimulator(phosphene_resolution=(phosphene_resolution,phosphene_resolution),\n",
    "                                                     size=(128,128),\n",
    "                                                     jitter=0.25,\n",
    "                                                     intensity_var=0.9,\n",
    "                                                     aperture=.66,\n",
    "                                                     sigma=0.60,)\n",
    "        else: \n",
    "            self.simulator = None\n",
    "    \n",
    "    def __call__(self,state_raw,):\n",
    "        frame = environment.state2usableArray(state_raw)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame = frame.astype('float32')\n",
    "        if self.simulator is not None:\n",
    "            frame = self.simulator(frame)\n",
    "    \n",
    "        return torch.Tensor(frame / 255.).view(1,1,self.imsize, self.imsize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp1_plain_phosNone_S0\n",
      "step count 25 wall_collisions: 25, box_collisions: 0, endless_loops: 5, total_reward: -255\n",
      "episode 0, target net updated\n",
      "episode 10, target net updated\n",
      "episode 20, target net updated\n",
      "episode 30, target net updated\n",
      "episode 40, target net updated\n",
      "step count 25 wall_collisions: 25, box_collisions: 0, endless_loops: 5, total_reward: -255\n",
      "episode 50, target net updated\n"
     ]
    }
   ],
   "source": [
    "## Training parameters \n",
    "MAX_EPISODES = 500 # number of episodes (an episode ends after agent hits a box)\n",
    "MAX_STEPS  = 5e4  # number of optimization steps (each time step the model parameters are updated)\n",
    "TRAINING_CONDITION = 0 # 0: plain training, 1: complex training, 2: plain testing 3: complex testing\n",
    "# LOGFILE = 'Out/test-10.csv'\n",
    "# MODEL_PATH = 'Out/test-10.pth'\n",
    "# SEED = 2\n",
    "RESET_UPON_END_SIGNAL = {0:False,  # Nothing happened\n",
    "                         1:True,   # Box collision\n",
    "                         2:False,   # Wall collision\n",
    "                         3:True}  # Reached step target\n",
    "RESET_AFTER_NR_SIDESTEPS = 5\n",
    "\n",
    "\n",
    "# Training configuration dictionary\n",
    "cfg = dict()\n",
    "# cfg['seed']                     = SEED\n",
    "cfg['training_condition']       = TRAINING_CONDITION\n",
    "cfg['max_episodes']             = MAX_EPISODES\n",
    "# cfg['model_path']               = MODEL_PATH\n",
    "cfg['max_steps']                = MAX_STEPS\n",
    "cfg['target_update']            = TARGET_UPDATE\n",
    "cfg['stack_size']               = STACK_SIZE\n",
    "cfg['reset_after_nr_sidesteps'] = RESET_AFTER_NR_SIDESTEPS\n",
    "cfg['reset_upon_end_signal']    = RESET_UPON_END_SIGNAL\n",
    "cfg['replay_start_size']        = REPLAY_START_SIZE\n",
    "# cfg['logfile']                  = LOGFILE\n",
    "\n",
    "\n",
    "for phosphene_resolution, seed in [(None,0),(None,1),(None,2),(None,3),(None,4),\n",
    "                                   (50,0),(50,1),(50,2),(50,3),(50,4),\n",
    "                                   (42,0),(42,1),(42,2),(42,3),(42,4),\n",
    "                                   (34,0),(34,1),(34,2),(34,3),(34,4),\n",
    "                                   (26,0),(26,1),(26,2),(26,3),(26,4),\n",
    "                                   (18,0),(18,1),(18,2),(18,3),(18,4),\n",
    "                                   (10,0),(10,1),(10,2),(10,3),(10,4),]:\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Condition-specific configuration\n",
    "    cfg['seed'] = seed\n",
    "    torch.manual_seed(seed)\n",
    "    model_name = 'exp1_plain_phos{}_S{}'.format(phosphene_resolution,seed)\n",
    "    print(model_name)\n",
    "    cfg['logfile'] = 'Out/Exp1/{}_train_stats.csv'.format(model_name)\n",
    "    cfg['model_path'] = 'Out/Exp1/{}_best_model.pth'.format(model_name)\n",
    "    \n",
    "    # Phosphene simulation\n",
    "    img_processing = ImageProcessor(phosphene_resolution = phosphene_resolution)\n",
    "    \n",
    "    # Re-initialize model and optimizer\n",
    "    agent = model.DoubleDQNAgent(imsize=IMSIZE,\n",
    "         in_channels=STACK_SIZE,\n",
    "         n_actions=N_ACTIONS,\n",
    "         memory_capacity=MEMORY_CAPACITY,\n",
    "         eps_start=EPS_START,\n",
    "         eps_end=EPS_END,\n",
    "         eps_delta=EPS_DECAY,\n",
    "         gamma_discount = GAMMA,\n",
    "         batch_size = BATCH_SIZE,\n",
    "         device=DEVICE)\n",
    "    \n",
    "    optimizer = optim.Adam(agent.policy_net.parameters(), lr = LR_DQN)\n",
    "\n",
    "    # Start training\n",
    "    training.train(agent, environment, img_processing, optimizer, cfg)\n",
    "    print('finished training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# EXAMPLES = 10\n",
    "\n",
    "# i = 0\n",
    "# bad_choices = [(state, action, next_state,reward) for (state, action, next_state,reward) in agent.memory.memory if reward<0 and action ==0]\n",
    "# # for state, action, next_state, reward in agent.memory.memory[:EXAMPLES]:\n",
    "# for state, action, next_state, reward in bad_choices[:EXAMPLES]:\n",
    "#     i+=1\n",
    "    \n",
    "#     plt.figure(figsize = (10,10), dpi=200)\n",
    "#     img = torch.cat([state[0,t,...] for t in range(STACK_SIZE)],dim=1)\n",
    "#     if next_state is not None:\n",
    "#         img = torch.cat([img, next_state[0,-1,...]],dim=1)\n",
    "#         plt.axvline(x=STACK_SIZE*IMSIZE,color='r')\n",
    "#     plt.imshow(img.detach().cpu().numpy())\n",
    "#     plt.title('Action: {}, Reward {}'.format(action.item(),reward.item()))\n",
    "#     plt.axis('off')\n",
    "#     plt.ylabel('frames >')\n",
    "#     plt.xlabel('state | next state')\n",
    "#     plt.show()\n",
    "    \n",
    "# # plt.tight_layout()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
