{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import datetime\n",
    "import os, sys\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple\n",
    "from itertools import count\n",
    "from IPython.display import Audio\n",
    "import csv\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "from torchsummary import summary\n",
    "\n",
    "import cv2\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# local files\n",
    "sys.path.insert(0, '../')\n",
    "import pyClient\n",
    "import utils\n",
    "import model\n",
    "from model import Transition\n",
    "import training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment parameters\n",
    "IMSIZE = 128\n",
    "STACK_SIZE = 4\n",
    "N_ACTIONS = 3\n",
    "IP  = \"127.0.0.1\" # Ip address that the TCP/IP interface listens to\n",
    "PORT = 13000       # Port number that the TCP/IP interface listens to\n",
    "\n",
    "environment =  pyClient.Environment(ip = IP, port = PORT, size = IMSIZE) # or choose # DummyEnvironment()\n",
    "\n",
    "\n",
    "# Model parameters\n",
    "BATCH_SIZE = 128 #original 128\n",
    "GAMMA = 0.3\n",
    "EPS_START = 0.95\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY_steps = 4000 \n",
    "EPS_DECAY = (EPS_START - EPS_END)/EPS_DECAY_steps\n",
    "REPLAY_START_SIZE =  1500\n",
    "TARGET_UPDATE = 10 #episodes\n",
    "DEVICE = 'cuda:0'\n",
    "MEMORY_CAPACITY = 12000\n",
    "\n",
    "# agent = model.DoubleDQNAgent(imsize=IMSIZE, \n",
    "#                  in_channels=STACK_SIZE,\n",
    "#                  n_actions=N_ACTIONS,\n",
    "#                  memory_capacity=MEMORY_CAPACITY,\n",
    "#                  eps_start=EPS_START,\n",
    "#                  eps_end=EPS_END,\n",
    "#                  eps_delta=EPS_DECAY,\n",
    "#                  gamma_discount = GAMMA,\n",
    "#                  batch_size = BATCH_SIZE,\n",
    "#                  device=DEVICE)\n",
    "\n",
    "\n",
    "# Optimizer Parameters\n",
    "LR_DQN = 0.0008\n",
    "\n",
    "# optimizer = optim.Adam(agent.policy_net.parameters(), lr = LR_DQN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing\n",
    "class ImageProcessor(object):\n",
    "    def __init__(self, phosphene_resolution=None, imsize=128):\n",
    "        \"\"\" @TODO \n",
    "        - Extended image processing\n",
    "        \"\"\"\n",
    "        self.imsize = imsize\n",
    "        if phosphene_resolution is not None:\n",
    "            self.simulator = utils.PhospheneSimulator(phosphene_resolution=(phosphene_resolution,phosphene_resolution),\n",
    "                                                     size=(128,128),\n",
    "                                                     jitter=0.25,\n",
    "                                                     intensity_var=0.9,\n",
    "                                                     aperture=.66,\n",
    "                                                     sigma=0.60,)\n",
    "        else: \n",
    "            self.simulator = None\n",
    "    \n",
    "    def __call__(self,state_raw,):\n",
    "        frame = environment.state2usableArray(state_raw)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame = frame.astype('float32')\n",
    "        if self.simulator is not None:\n",
    "            frame = self.simulator(frame)\n",
    "    \n",
    "        return torch.Tensor(frame / 255.).view(1,1,self.imsize, self.imsize)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "exp1_complex_phos18_S0_LR00002_gamma02\n",
      "step count 25 wall_collisions: 25, box_collisions: 0, endless_loops: 5, total_reward: -25.5\n",
      "episode 0, target net updated\n"
     ]
    }
   ],
   "source": [
    "## Training parameters \n",
    "MAX_EPISODES = 800 # number of episodes (an episode ends after agent hits a box)\n",
    "MAX_STEPS  = 5e4  # number of optimization steps (each time step the model parameters are updated)\n",
    "RESET_UPON_END_SIGNAL = {0:False,  # Nothing happened\n",
    "                         1:True,   # Box collision\n",
    "                         2:False,   # Wall collision\n",
    "                         3:True}  # Reached step target\n",
    "RESET_AFTER_NR_SIDESTEPS = 5\n",
    "\n",
    "\n",
    "# Training configuration dictionary\n",
    "cfg = dict()\n",
    "# cfg['seed']                     = SEED\n",
    "# cfg['training_condition']       = TRAINING_CONDITION \n",
    "cfg['max_episodes']             = MAX_EPISODES\n",
    "# cfg['model_path']               = MODEL_PATH\n",
    "cfg['max_steps']                = MAX_STEPS\n",
    "cfg['target_update']            = TARGET_UPDATE\n",
    "cfg['stack_size']               = STACK_SIZE\n",
    "cfg['reset_after_nr_sidesteps'] = RESET_AFTER_NR_SIDESTEPS\n",
    "cfg['reset_upon_end_signal']    = RESET_UPON_END_SIGNAL\n",
    "cfg['replay_start_size']        = REPLAY_START_SIZE\n",
    "# cfg['logfile']                  = LOGFILE\n",
    "\n",
    "for seed in [0,1,2,3,4]:\n",
    "    for complexity in ['plain', 'complex']:\n",
    "        for phosphene_resolution in [None, 50,42,34,26,18,10]:\n",
    "\n",
    "\n",
    "        # Condition-specific configuration\n",
    "        cfg['training_condition'] = 0 if complexity == 'plain' else 1 # 0: plain training, 1: complex training, 2: plain testing 3: complex testing\n",
    "        cfg['seed'] = seed\n",
    "        torch.manual_seed(seed)\n",
    "        model_name = 'exp1_{}_phos{}_S{}'.format(complexity,phosphene_resolution,seed)\n",
    "        print(model_name)\n",
    "        cfg['logfile'] = 'Out/Exp1/{}_train_stats.csv'.format(model_name)\n",
    "        cfg['model_path'] = 'Out/Exp1/{}_best_model.pth'.format(model_name)\n",
    "\n",
    "        # Phosphene simulation\n",
    "        img_processing = ImageProcessor(phosphene_resolution = phosphene_resolution)\n",
    "\n",
    "        # Re-initialize model and optimizer\n",
    "        agent = model.DoubleDQNAgent(imsize=IMSIZE,\n",
    "             in_channels=STACK_SIZE,\n",
    "             n_actions=N_ACTIONS,\n",
    "             memory_capacity=MEMORY_CAPACITY,\n",
    "             eps_start=EPS_START,\n",
    "             eps_end=EPS_END,\n",
    "             eps_delta=EPS_DECAY,\n",
    "             gamma_discount = GAMMA,\n",
    "             batch_size = BATCH_SIZE,\n",
    "             device=DEVICE)\n",
    "\n",
    "        optimizer = optim.Adam(agent.policy_net.parameters(), lr = LR_DQN)\n",
    "\n",
    "        # Start training\n",
    "        training.train(agent, environment, img_processing, optimizer, cfg)\n",
    "        print('finished training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Debugging:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize replay memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# EXAMPLES = 10\n",
    "\n",
    "# i = 0\n",
    "# bad_choices = [(state, action, next_state,reward) for (state, action, next_state,reward) in agent.memory.memory]# if reward<0 and action ==0]\n",
    "# # for state, action, next_state, reward in agent.memory.memory[:EXAMPLES]:\n",
    "# for state, action, next_state, reward in bad_choices[:EXAMPLES]:\n",
    "#     i+=1\n",
    "    \n",
    "#     plt.figure(figsize = (10,10), dpi=200)\n",
    "#     img = torch.cat([state[0,t,...] for t in range(STACK_SIZE)],dim=1)\n",
    "#     if next_state is not None:\n",
    "#         img = torch.cat([img, next_state[0,-1,...]],dim=1)\n",
    "#         plt.axvline(x=STACK_SIZE*IMSIZE,color='r')\n",
    "#     plt.imshow(img.detach().cpu().numpy())\n",
    "#     plt.title('Action: {}, Reward {}'.format(action.item(),reward.item()))\n",
    "#     plt.axis('off')\n",
    "#     plt.ylabel('frames >')\n",
    "#     plt.xlabel('state | next state')\n",
    "#     plt.show()\n",
    "    \n",
    "# # plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting q-value predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_action_values, expected_state_action_values = agent.forward()\n",
    "# transitions = agent.memory.sample(agent.batch_size)\n",
    "# # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "# # detailed explanation). This converts batch-array of Transitions\n",
    "# # to Transition of batch-arrays.\n",
    "# batch = Transition(*zip(*transitions))\n",
    "\n",
    "# # Compute a mask of non-final states and concatenate the batch elements\n",
    "# # (a final state would've been the one after which simulation ended)\n",
    "# non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "#                                       batch.next_state)), device=agent.device, dtype=torch.bool)\n",
    "# non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "#                                             if s is not None])\n",
    "# state_batch = torch.cat(batch.state)\n",
    "# action_batch = torch.cat(batch.action)\n",
    "# reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "# # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "# # columns of actions taken. These are the actions which would've been taken\n",
    "# # for each batch state according to policy_net\n",
    "# pred = agent.policy_net(state_batch)\n",
    "\n",
    "# EXAMPLES = 50\n",
    "\n",
    "# actions = action_batch[:EXAMPLES].detach().cpu().numpy()\n",
    "# rewards = reward_batch[:EXAMPLES].detach().cpu().numpy()\n",
    "# predicted = pred[:EXAMPLES].detach().cpu().numpy().squeeze()\n",
    "# obtained = np.zeros((EXAMPLES,3))\n",
    "# for i in range(EXAMPLES):\n",
    "#     obtained[i,actions[i]] = rewards[i]\n",
    "\n",
    "# plt.figure(figsize=(10,10),dpi=100)\n",
    "# plt.subplot(1,2,1)\n",
    "# plt.imshow(predicted)\n",
    "# plt.subplot(1,2,2)\n",
    "# plt.imshow(obtained)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize an episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset environment at start of episode\n",
    "seed = torch.randint(250,(1,)).item()\n",
    "_, _, _ = environment.setRandomSeed(seed)\n",
    "_, _, _ = environment.reset(cfg['training_condition'])\n",
    "\n",
    "# Create an empty frame stack and fill it with frames\n",
    "frame_stack = utils.FrameStack(stack_size=cfg['stack_size'] )\n",
    "for _ in range(cfg['stack_size'] ):\n",
    "    _, _, frame_raw = environment.step(0)\n",
    "    frame = img_processing(frame_raw).to(agent.device) \n",
    "    state = frame_stack.update_with(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for t in count(): \n",
    "\n",
    "#     agent.policy_net.eval()\n",
    "#     # Agent performs a step (based on the current state) and obtains next state\n",
    "#     action = agent.select_action(state)\n",
    "#     end, reward, frame_raw = environment.step(action.item())\n",
    "#     agent_died = cfg['reset_upon_end_signal'][end] # or side_steps > cfg['reset_after_nr_sidesteps']\n",
    "#     frame = img_processing(frame_raw).to(agent.device)\n",
    "#     next_state = frame_stack.update_with(frame) if not agent_died else None\n",
    "#     pred = agent.policy_net(state).argmax(axis=1)\n",
    "    \n",
    "#     # Interpret reward signal\n",
    "#     if reward > 100:\n",
    "#         reward = -(reward -100)\n",
    "#     reward /= 10\n",
    "    \n",
    "#     # Visualize state and print pred, action and reward\n",
    "#     plt.figure(figsize = (10,10), dpi=200)\n",
    "#     img = torch.cat([state[0,t,...] for t in range(STACK_SIZE)],dim=1)\n",
    "#     if next_state is not None:\n",
    "#         img = torch.cat([img, next_state[0,-1,...]],dim=1)\n",
    "#         plt.axvline(x=STACK_SIZE*IMSIZE,color='r')\n",
    "#     plt.imshow(img.detach().cpu().numpy())\n",
    "#     plt.title('Action: {}, Reward {}'.format(action.item(),reward))\n",
    "#     plt.axis('off')\n",
    "#     plt.ylabel('frames >')\n",
    "#     plt.xlabel('state | next state')\n",
    "#     plt.show()\n",
    "#     print('Pred: {}'.format(pred.item()))\n",
    "#     print('Action: {}'.format(action.item()))\n",
    "#     print('Reward: {}\\n'.format(reward))\n",
    "\n",
    "#     # the episode ends here if agent performed any 'lethal' action (specified in RESET_UPON_END_SIGNAL)\n",
    "#     if agent_died:\n",
    "#         break\n",
    "#     else:\n",
    "#         state = next_state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Toy environment for debugging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class DummyEnvironment:\n",
    "#     def __init__(self, ip = \"127.0.0.1\", port = 13000, size = 128, channels=16):\n",
    "#         self.size = size\n",
    "#         self.channels = channels\n",
    "#         self._maxSteps = 100\n",
    "#         self.reset()\n",
    " \n",
    "#     def reset(self, kind=0):\n",
    "#         self._state = 1\n",
    "#         self._steps = 0\n",
    "#         return self._receive()\n",
    "\n",
    "#     def step(self, action):\n",
    "#         self._state = -self._state\n",
    "#         self._steps += 1\n",
    "#         return self._receive(action)\n",
    "    \n",
    "#     def setRandomSeed(self, action):\n",
    "#         return self._receive()\n",
    "\n",
    "#     def _receive(self,action=0):\n",
    "#         end    = 0 if self._steps < self._maxSteps else 3\n",
    "#         reward = {0:-self._state, 1:self._state, 2:-2}[action]\n",
    "#         state  = [150-100*self._state for _ in range(262144)] # raw state\n",
    "#         return end, reward, state\n",
    "    \n",
    "#     def state2arrays(self,state):\n",
    "#         if self.channels == 3:\n",
    "#             return {'colors' : self.state2usableArray(state),}\n",
    "        \n",
    "#         else:\n",
    "#             state  = np.array(state, \"uint8\").reshape(self.size, self.size, self.channels)\n",
    "#             arrays = {'colors' : state[...,:3],\n",
    "#                     'objseg' : state[...,3:6],\n",
    "#                     'semseg': state[...,6:9],\n",
    "#                     'normals'   : state[...,9:12],\n",
    "#                     'flow'   : state[...,12:15],\n",
    "#                     'depth'  : state[...,15]}\n",
    "#             return arrays\n",
    "    \n",
    "#     def state2usableArray(self, state):\n",
    "#         return np.array(state, \"uint8\").reshape(self.size, self.size, 16)[...,:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fast evaluation of trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "MODEL_NAME = 'exp1_plain_phosNone_S0'\n",
    "\n",
    "stats = pd.read_csv('./Out/Exp1/{}_train_stats.csv'.format(MODEL_NAME))\n",
    "\n",
    "plt.figure(figsize = (16,4),dpi=200)\n",
    "plt.subplot(1,2,1)\n",
    "sns.lineplot(data= stats.loc[stats.validation==0],x='episode', y='reward')\n",
    "plt.plot(np.convolve(stats.loc[stats.validation==0].reward,np.ones(10)/10,mode='valid'))\n",
    "plt.title('training performance')\n",
    "plt.legend(['training_reward', 'running average (N=10)'])\n",
    "plt.subplot(1,2,2)\n",
    "sns.lineplot(data= stats.loc[stats.validation==1],x='episode', y='reward')\n",
    "plt.title('validation performance')\n",
    "plt.legend(['validation_reward'])\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize = (16,4))\n",
    "sns.lineplot(data= stats.loc[stats.validation==0],x='episode', y='train_loss')\n",
    "plt.title('training curves')\n",
    "plt.legend(['Train Loss'])\n",
    "\n",
    "plt.figure(figsize = (16,4))\n",
    "sns.lineplot(data= stats.loc[stats.validation==0],x='episode', y='epsilon')\n",
    "plt.title('training curves')\n",
    "plt.legend(['Train Loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further testing and evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import os, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np \n",
    "\n",
    "# # local files\n",
    "sys.path.insert(0, '../')\n",
    "import pyClient\n",
    "import utils\n",
    "import model\n",
    "from model import Transition\n",
    "from testing import test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run models on test environment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Image processing\n",
    "class ImageProcessor(object):\n",
    "    def __init__(self, phosphene_resolution=None, imsize=128):\n",
    "        \"\"\" @TODO \n",
    "        - Extended image processing\n",
    "        \"\"\"\n",
    "        self.imsize = imsize\n",
    "        if phosphene_resolution is not None:\n",
    "            self.simulator = utils.PhospheneSimulator(phosphene_resolution=(phosphene_resolution,phosphene_resolution),\n",
    "                                                     size=(128,128),\n",
    "                                                     jitter=0.25,\n",
    "                                                     intensity_var=0.9,\n",
    "                                                     aperture=.66,\n",
    "                                                     sigma=0.60,)\n",
    "        else: \n",
    "            self.simulator = None\n",
    "    \n",
    "    def __call__(self,state_raw,):\n",
    "        frame = environment.state2usableArray(state_raw)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "        frame = frame.astype('float32')\n",
    "        if self.simulator is not None:\n",
    "            frame = self.simulator(frame)\n",
    "    \n",
    "        return torch.Tensor(frame / 255.).view(1,1,self.imsize, self.imsize)\n",
    "    \n",
    "img_processing = ImageProcessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Environment parameters\n",
    "IMSIZE = 128\n",
    "STACK_SIZE = 4\n",
    "N_ACTIONS = 3\n",
    "IP  = \"127.0.0.1\" # Ip address that the TCP/IP interface listens to\n",
    "PORT = 13000       # Port number that the TCP/IP interface listens to\n",
    "\n",
    "environment = pyClient.Environment(ip = IP, port = PORT, size = IMSIZE) \n",
    "\n",
    "# Model parameters\n",
    "BATCH_SIZE = 128 #original 128\n",
    "DEVICE = 'cuda:0'\n",
    "\n",
    "agent = model.DoubleDQNAgent(imsize=IMSIZE,\n",
    "                 in_channels=STACK_SIZE,\n",
    "                 n_actions=N_ACTIONS,\n",
    "                 device=DEVICE)\n",
    "\n",
    "\n",
    "## Testing parameters \n",
    "RESET_UPON_END_SIGNAL = {0:False,  # Nothing happened\n",
    "                         1:False,   # Box collision\n",
    "                         2:False,   # Wall collision\n",
    "                         3:True}  # Reached step target\n",
    "RESET_AFTER_NR_SIDESTEPS = 5\n",
    "\n",
    "\n",
    "# Testing configuration dictionary\n",
    "cfg = dict()\n",
    "cfg['stack_size']               = STACK_SIZE\n",
    "cfg['reset_after_nr_sidesteps'] = RESET_AFTER_NR_SIDESTEPS\n",
    "cfg['reset_upon_end_signal']    = RESET_UPON_END_SIGNAL\n",
    "\n",
    "test_data = []\n",
    "for complexity in ['plain', 'complex']:\n",
    "    for phosphene_resolution in [None, 50,42,34,26,18,10]:\n",
    "        for seed in [0,1,2,3,4]:\n",
    "            \n",
    "            # Condition-specific configuration\n",
    "            cfg['training_condition']       = 2 if complexity == 'plain' else 3 # 0: plain training, 1: complex training, 2: plain testing 3: complex testing\n",
    "            model_name = 'exp1_{}_phos{}_S{}'.format(complexity, phosphene_resolution,seed)\n",
    "            model_path = 'Out/Exp1/{}_best_model.pth'.format(model_name)\n",
    "            print(model_name)\n",
    "\n",
    "            # Phosphene simulation\n",
    "            img_processing = ImageProcessor(phosphene_resolution = phosphene_resolution)\n",
    "\n",
    "            # Re-initialize model and optimizer\n",
    "            agent = model.DoubleDQNAgent(imsize=IMSIZE,\n",
    "                 in_channels=STACK_SIZE,\n",
    "                 n_actions=N_ACTIONS,\n",
    "                 device=DEVICE)\n",
    "            agent.policy_net.load_state_dict(torch.load(model_path,map_location=DEVICE))\n",
    "\n",
    "            # Testing\n",
    "            conditions = {'complexity': complexity, 'phosphene_resolution': phosphene_resolution, 'seed' : seed}\n",
    "            results = test(agent, environment, img_processing, cfg)\n",
    "            test_data.append({**conditions,**results})\n",
    "data = pd.DataFrame(test_data)\n",
    "data.to_csv('Out/Exp1/_test_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('./Out/Exp1/_test_results.csv') \n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(data=test_data,x='phosphene_resolution', y='box_collisions', hue='complexity')\n",
    "plt.show()\n",
    "sns.lineplot(data=test_data,x='phosphene_resolution', y='wall_collisions', hue='complexity')\n",
    "plt.show()\n",
    "sns.lineplot(data=test_data,x='phosphene_resolution', y='cumulative_reward', hue='complexity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training and validation curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_stats = pd.DataFrame()\n",
    "best_stats = pd.DataFrame()\n",
    "for complexity in ['plain', 'complex']:\n",
    "    for phosphene_resolution in [None, 50,42,34,26,18,10]:\n",
    "        for seed in [0,1,2,3,4]:\n",
    "            model_name = 'exp1_{}_phos{}_S{}'.format(complexity, phosphene_resolution,seed)\n",
    "            train_csv = './Out/Exp1/{}_train_stats.csv'.format(model_name)\n",
    "            train_stats = pd.read_csv(train_csv)\n",
    "            train_stats['complexity'] = complexity\n",
    "            train_stats['resolution'] = phosphene_resolution\n",
    "            train_stats['seed'] = seed\n",
    "            train_stats['model_name'] = model_name\n",
    "            \n",
    "            # append all rows\n",
    "            all_stats = all_stats.append(train_stats,ignore_index=True)\n",
    "            \n",
    "            # append only best-performing validation row\n",
    "            val = train_stats.loc[train_stats.validation==1].reset_index()\n",
    "            best_stats = best_stats.append(val.iloc[[val.reward.idxmax()]], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MODEL_NAME = 'exp1_plain_phos18_S2'\n",
    "\n",
    "stats = all_stats.loc[all_stats.model_name==MODEL_NAME]\n",
    "\n",
    "plt.figure(figsize = (16,4))\n",
    "plt.subplot(1,2,1)\n",
    "sns.lineplot(data= stats.loc[stats.validation==0],x='episode', y='reward')\n",
    "plt.plot(np.convolve(stats.loc[stats.validation==0].reward,np.ones(10)/10,mode='valid'))\n",
    "plt.title('training performance')\n",
    "plt.legend(['training_reward', 'running average (N=10)'])\n",
    "plt.subplot(1,2,2)\n",
    "sns.lineplot(data= stats.loc[stats.validation==1],x='episode', y='reward')\n",
    "plt.title('validation performance')\n",
    "plt.legend(['validation_reward'])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in ['reward', 'step_count', 'wall_collisions', 'box_collisions', 'endless_loops']:\n",
    "    sns.lineplot(data=best_stats, x='resolution',y=y,hue='complexity')\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
